{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2938c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# import third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da0c6787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "DATA_DIR = Path.cwd() / \"data/\"\n",
    "STANDARD_DEPTHS = np.array(\n",
    "    [\n",
    "        0,\n",
    "        10,\n",
    "        20,\n",
    "        30,\n",
    "        50,\n",
    "        75,\n",
    "        100,\n",
    "        125,\n",
    "        150,\n",
    "        200,\n",
    "        250,\n",
    "        300,\n",
    "        400,\n",
    "        500,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af79d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_data_array(param_name: str, sdate: str, edate: str) -> np.ndarray:\n",
    "    data_list = []\n",
    "    sdate_dt = datetime.strptime(sdate, \"%Y-%m-%d\")\n",
    "    edate_dt = datetime.strptime(edate, \"%Y-%m-%d\")\n",
    "    start_year = sdate_dt.year\n",
    "    end_year = edate_dt.year\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for month in range(1, 13):\n",
    "            f = DATA_DIR / f\"sooList_{year}{month:02d}.json\"\n",
    "            if not f.is_file():\n",
    "                continue\n",
    "            df = pd.read_json(f)\n",
    "            arr = df[param_name].replace([\"\", None], np.nan)\n",
    "            data_list.append(arr.values)\n",
    "    if data_list:\n",
    "        return np.concatenate(data_list)\n",
    "    return np.array([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d28d96eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m edate = \u001b[33m\"\u001b[39m\u001b[33m2024-12-31\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m temperature = concat_data_array(\u001b[33m\"\u001b[39m\u001b[33mwtr_tmp\u001b[39m\u001b[33m\"\u001b[39m, sdate, edate)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m depth = \u001b[43mconcat_data_array\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwtr_dep\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m obs_time = concat_data_array(\u001b[33m\"\u001b[39m\u001b[33mobs_dtm\u001b[39m\u001b[33m\"\u001b[39m, sdate, edate)\n\u001b[32m      7\u001b[39m longitude = concat_data_array(\u001b[33m\"\u001b[39m\u001b[33mlon\u001b[39m\u001b[33m\"\u001b[39m, sdate, edate)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mconcat_data_array\u001b[39m\u001b[34m(param_name, sdate, edate)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.is_file():\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m arr = df[param_name].replace([\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m], np.nan)\n\u001b[32m     14\u001b[39m data_list.append(arr.values)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyunw\\miniforge3\\envs\\py313\\Lib\\site-packages\\pandas\\io\\json\\_json.py:815\u001b[39m, in \u001b[36mread_json\u001b[39m\u001b[34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[39m\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[32m    814\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyunw\\miniforge3\\envs\\py313\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1014\u001b[39m, in \u001b[36mJsonReader.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1012\u001b[39m         obj = \u001b[38;5;28mself\u001b[39m._get_object_parser(\u001b[38;5;28mself\u001b[39m._combine_lines(data_lines))\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.convert_dtypes(\n\u001b[32m   1017\u001b[39m         infer_objects=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype_backend=\u001b[38;5;28mself\u001b[39m.dtype_backend\n\u001b[32m   1018\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyunw\\miniforge3\\envs\\py313\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1040\u001b[39m, in \u001b[36mJsonReader._get_object_parser\u001b[39m\u001b[34m(self, json)\u001b[39m\n\u001b[32m   1038\u001b[39m obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33mframe\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1040\u001b[39m     obj = \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33mseries\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1043\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyunw\\miniforge3\\envs\\py313\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1182\u001b[39m, in \u001b[36mParser.parse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.convert_axes:\n\u001b[32m   1181\u001b[39m     \u001b[38;5;28mself\u001b[39m._convert_axes()\n\u001b[32m-> \u001b[39m\u001b[32m1182\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_convert_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyunw\\miniforge3\\envs\\py313\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1458\u001b[39m, in \u001b[36mFrameParser._try_convert_types\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1455\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.convert_dates:\n\u001b[32m   1456\u001b[39m     \u001b[38;5;28mself\u001b[39m._try_convert_dates()\n\u001b[32m-> \u001b[39m\u001b[32m1458\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_converter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1459\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_convert_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1460\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyunw\\miniforge3\\envs\\py313\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1448\u001b[39m, in \u001b[36mFrameParser._process_converter\u001b[39m\u001b[34m(self, f, filt)\u001b[39m\n\u001b[32m   1444\u001b[39m     new_obj[i] = c\n\u001b[32m   1446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m needs_new_obj:\n\u001b[32m   1447\u001b[39m     \u001b[38;5;66;03m# possibly handle dup columns\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m     new_frame = \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1449\u001b[39m     new_frame.columns = obj.columns\n\u001b[32m   1450\u001b[39m     \u001b[38;5;28mself\u001b[39m.obj = new_frame\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyunw\\miniforge3\\envs\\py313\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyunw\\miniforge3\\envs\\py313\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyunw\\miniforge3\\envs\\py313\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    149\u001b[39m axes = [columns, index]\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33mblock\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_column_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrefs\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyunw\\miniforge3\\envs\\py313\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2144\u001b[39m, in \u001b[36mcreate_block_manager_from_column_arrays\u001b[39m\u001b[34m(arrays, axes, consolidate, refs)\u001b[39m\n\u001b[32m   2142\u001b[39m     raise_construction_error(\u001b[38;5;28mlen\u001b[39m(arrays), arrays[\u001b[32m0\u001b[39m].shape, axes, e)\n\u001b[32m   2143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[32m-> \u001b[39m\u001b[32m2144\u001b[39m     \u001b[43mmgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2145\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mgr\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyunw\\miniforge3\\envs\\py313\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1788\u001b[39m, in \u001b[36mBlockManager._consolidate_inplace\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1783\u001b[39m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[32m   1784\u001b[39m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[32m   1785\u001b[39m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[32m   1786\u001b[39m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[32m   1787\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_consolidated():\n\u001b[32m-> \u001b[39m\u001b[32m1788\u001b[39m         \u001b[38;5;28mself\u001b[39m.blocks = \u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m         \u001b[38;5;28mself\u001b[39m._is_consolidated = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1790\u001b[39m         \u001b[38;5;28mself\u001b[39m._known_consolidated = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyunw\\miniforge3\\envs\\py313\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2269\u001b[39m, in \u001b[36m_consolidate\u001b[39m\u001b[34m(blocks)\u001b[39m\n\u001b[32m   2267\u001b[39m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] = []\n\u001b[32m   2268\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[32m-> \u001b[39m\u001b[32m2269\u001b[39m     merged_blocks, _ = \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2270\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[32m   2271\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2272\u001b[39m     new_blocks = extend_blocks(merged_blocks, new_blocks)\n\u001b[32m   2273\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyunw\\miniforge3\\envs\\py313\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2304\u001b[39m, in \u001b[36m_merge_blocks\u001b[39m\u001b[34m(blocks, dtype, can_consolidate)\u001b[39m\n\u001b[32m   2301\u001b[39m     new_values = new_values[argsort]\n\u001b[32m   2302\u001b[39m     new_mgr_locs = new_mgr_locs[argsort]\n\u001b[32m-> \u001b[39m\u001b[32m2304\u001b[39m     bp = \u001b[43mBlockPlacement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_mgr_locs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2305\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [new_block_2d(new_values, placement=bp)], \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2307\u001b[39m \u001b[38;5;66;03m# can't consolidate --> no merge\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "sdate = \"1968-01-01\"\n",
    "edate = \"2024-12-31\"\n",
    "temperature = concat_data_array(\"wtr_tmp\", sdate, edate)\n",
    "depth = concat_data_array(\"wtr_dep\", sdate, edate)\n",
    "obs_time = concat_data_array(\"obs_dtm\", sdate, edate)\n",
    "longitude = concat_data_array(\"lon\", sdate, edate)\n",
    "latitude = concat_data_array(\"lat\", sdate, edate)\n",
    "salinity = concat_data_array(\"sal\", sdate, edate)\n",
    "dissolved_oxygen = concat_data_array(\"dox\", sdate, edate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_sparse_to_netcdf_spatiotemporal(\n",
    "    df: pd.DataFrame, filename: str, output_dir: str = DATA_DIR\n",
    ") -> None:\n",
    "    t_vals = np.sort(pd.to_datetime(df[\"datetime\"].unique()))\n",
    "    x_vals = np.sort(df[\"longitude\"].unique())\n",
    "    y_vals = np.sort(df[\"latitude\"].unique())\n",
    "    z_vals = np.sort(df[\"depth\"].unique())\n",
    "\n",
    "    t_index = {v: i for i, v in enumerate(t_vals)}\n",
    "    x_index = {v: i for i, v in enumerate(x_vals)}\n",
    "    y_index = {v: i for i, v in enumerate(y_vals)}\n",
    "    z_index = {v: i for i, v in enumerate(z_vals)}\n",
    "\n",
    "    t_idx, x_idx, y_idx, z_idx = [], [], [], []\n",
    "    wtr_tmp_data, sal_data, dox_data = [], [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if (\n",
    "            pd.isna(row[\"datetime\"])\n",
    "            or np.isnan(row[\"longitude\"])\n",
    "            or np.isnan(row[\"latitude\"])\n",
    "            or np.isnan(row[\"depth\"])\n",
    "        ):\n",
    "            continue\n",
    "        if not (\n",
    "            np.isnan(row[\"temperature\"])\n",
    "            and np.isnan(row[\"salinity\"])\n",
    "            and np.isnan(row[\"dissolved_oxygen\"])\n",
    "        ):\n",
    "            t_idx.append(t_index[pd.to_datetime(row[\"datetime\"])])\n",
    "            x_idx.append(x_index[row[\"longitude\"]])\n",
    "            y_idx.append(y_index[row[\"latitude\"]])\n",
    "            z_idx.append(z_index[row[\"depth\"]])\n",
    "            wtr_tmp_data.append(np.float32(row[\"temperature\"]))\n",
    "            sal_data.append(np.float32(row[\"salinity\"]))\n",
    "            dox_data.append(np.float32(row[\"dissolved_oxygen\"]))\n",
    "\n",
    "    n_obs = len(t_idx)\n",
    "\n",
    "    with nc.Dataset(filename, \"w\", format=\"NETCDF4\") as ds:\n",
    "        ds.createDimension(\"n_obs\", n_obs)\n",
    "        ds.createDimension(\"t\", len(t_vals))\n",
    "        ds.createDimension(\"x\", len(x_vals))\n",
    "        ds.createDimension(\"y\", len(y_vals))\n",
    "        ds.createDimension(\"z\", len(z_vals))\n",
    "\n",
    "        # Coordinate variables\n",
    "        time_var = ds.createVariable(\"t\", \"str\", (\"t\",))\n",
    "        time_var[:] = np.array([str(dt) for dt in t_vals])\n",
    "        ds.createVariable(\"x\", \"f4\", (\"x\",))[:] = x_vals\n",
    "        ds.createVariable(\"y\", \"f4\", (\"y\",))[:] = y_vals\n",
    "        ds.createVariable(\"z\", \"f4\", (\"z\",))[:] = z_vals\n",
    "\n",
    "        # Index variables\n",
    "        ds.createVariable(\"t_idx\", \"i4\", (\"n_obs\",))[:] = np.array(t_idx, dtype=np.int32)\n",
    "        ds.createVariable(\"x_idx\", \"i4\", (\"n_obs\",))[:] = np.array(x_idx, dtype=np.int32)\n",
    "        ds.createVariable(\"y_idx\", \"i4\", (\"n_obs\",))[:] = np.array(y_idx, dtype=np.int32)\n",
    "        ds.createVariable(\"z_idx\", \"i4\", (\"n_obs\",))[:] = np.array(z_idx, dtype=np.int32)\n",
    "\n",
    "        # Sparse data variables as float32\n",
    "        ds.createVariable(\"wtr_tmp\", \"f4\", (\"n_obs\",), fill_value=np.nan)[:] = np.array(\n",
    "            wtr_tmp_data, dtype=np.float32\n",
    "        )\n",
    "        ds.createVariable(\"sal\", \"f4\", (\"n_obs\",), fill_value=np.nan)[:] = np.array(\n",
    "            sal_data, dtype=np.float32\n",
    "        )\n",
    "        ds.createVariable(\"dox\", \"f4\", (\"n_obs\",), fill_value=np.nan)[:] = np.array(\n",
    "            dox_data, dtype=np.float32\n",
    "        )\n",
    "\n",
    "        ds.title = \"KODC Serial Oceanographic Observation Data\"\n",
    "        ds.history = \"Created by script (sparse spatiotemporal representation)\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b17f61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
